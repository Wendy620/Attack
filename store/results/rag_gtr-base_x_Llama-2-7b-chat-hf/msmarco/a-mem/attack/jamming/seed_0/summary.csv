backend,dataset,llm_model,k,N,jsr_paper,blocker@1,ASR_legacy,rule,oracle,blocker_style,blocker_ratio
a-mem,msmarco,Llama-2-7b-chat-hf,5,100,0.990,0.940,,jsr_paper = blocker@k; ASR=contains(resp_tar),emb=gtr-base; llm=gpt-4o-mini,dropout,1.00
